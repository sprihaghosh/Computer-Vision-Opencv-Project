{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAruco(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    key = getattr(aruco,f'DICT_5X5_250')\n",
    "    arucoDict = aruco.Dictionary_get(key)\n",
    "    arucoPara = aruco.DetectorParameters_create()\n",
    "\n",
    "    (corners,ids,rejected) = cv2.aruco.detectMarkers(img, arucoDict, parameters = arucoPara)\n",
    "\n",
    "    print(ids)\n",
    "    if len(corners) > 0:\n",
    "        ids = ids.flatten()\n",
    "\n",
    "        for (markerCorner,markerid) in zip(corners,ids):\n",
    "            corners = markerCorner.reshape((4,2))\n",
    "            (topLeft,topRight,bottomLeft,bottomRight) = corners\n",
    "\n",
    "            topRight = (int(topRight[0]),int(topRight[1]))\n",
    "            topLeft = (int(topLeft[0]),int(topLeft[1]))\n",
    "            bottomLeft = (int(bottomLeft[0]),int(bottomLeft[1]))\n",
    "            bottomRight = (int(bottomRight[0]),int(bottomRight[1]))\n",
    "\n",
    "            cx = int((topLeft[0]+bottomRight[0])/2.0)\n",
    "            cy = int((topLeft[1]+bottomRight[1])/2.0)\n",
    "\n",
    "            cx1 = int((topLeft[0]+bottomLeft[0])/2.0)\n",
    "            cy1 = int((topLeft[1]+bottomLeft[1])/2.0)\n",
    "\n",
    "            #sliced_img = img[topLeft[1]:bottomLeft[1],bottomLeft[0]:bottomRight[0]]\n",
    "\n",
    "            cv2.circle(img, (cx,cy),5,(255,0,0),-1)\n",
    "            cv2.circle(img, (cx1,cy1),5,(255,0,0),-1)\n",
    "            cv2.line(img,(cx,cy),(cx1,cy1),(255,0,0),2)\n",
    "\n",
    "            slope = (cy1-cy)/(cx1-cx)\n",
    "            angle = (math.atan(slope)) * 180 / math.pi\n",
    "            cv2.putText(img,str(angle),(cx,cy+10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "            # Generating a rotation matrix \n",
    "\n",
    "            matrix = cv2.getRotationMatrix2D((cx,cy), angle, 1.0) \n",
    "            h,w,c = img.shape\n",
    "\n",
    "  \n",
    "            # Performing the affine transformation \n",
    "\n",
    "            rotated = cv2.warpAffine(img, matrix, (w, h))\n",
    "\n",
    "            #cropped_img = rotated[topLeft[1]:bottomRight[1],topLeft[0]:bottomRight[0]]\n",
    "            #cropped_img = rotated[99:513,99:513]\n",
    "\n",
    "            aruco_dict[markerid] = rotated\n",
    "            #aruco_dict[markerid] = cropped_img\n",
    "\n",
    "            cv2.imshow(\"image\",img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            #cv2.imshow(\"Rotated image\",cropped_img)\n",
    "            cv2.imshow(\"Rotated image\",rotated)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]]\n",
      "[[4]]\n",
      "[[1]]\n",
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "img_a = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\Ha.jpg\")\n",
    "img_b = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\HaHa.jpg\")\n",
    "img_c = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\LMAO.jpg\")\n",
    "img_d = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\XD.jpg\")\n",
    "\n",
    "findAruco(img_a)\n",
    "findAruco(img_b)\n",
    "findAruco(img_c)\n",
    "findAruco(img_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_aruco_dict = {}\n",
    "\n",
    "#SCREEN_DIMENSIONS = (591,591)\n",
    "\n",
    "#def to_pixel_coords(relative_coords):\n",
    " #   return tuple(round(coord * dimension) for coord, dimension in zip(relative_coords, SCREEN_DIMENSIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_aruco(img2):\n",
    "    gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    key = getattr(aruco,f'DICT_5X5_250')\n",
    "    arucoDict = aruco.Dictionary_get(key)\n",
    "    arucoPara = aruco.DetectorParameters_create()\n",
    "\n",
    "    (corners,ids,rejected) = cv2.aruco.detectMarkers(img2, arucoDict, parameters = arucoPara)\n",
    "\n",
    "    print(ids)\n",
    "    if len(corners) > 0:\n",
    "        ids = ids.flatten()\n",
    "\n",
    "        for (markerCorner,markerid) in zip(corners,ids):\n",
    "            corners = markerCorner.reshape((4,2))\n",
    "            (topLeft,topRight,bottomLeft,bottomRight) = corners\n",
    "\n",
    "            topRight = (int(topRight[0]),int(topRight[1]))\n",
    "            topLeft = (int(topLeft[0]),int(topLeft[1]))\n",
    "            bottomLeft = (int(bottomLeft[0]),int(bottomLeft[1]))\n",
    "            bottomRight = (int(bottomRight[0]),int(bottomRight[1]))\n",
    "\n",
    "            #print(bottomLeft[0],bottomRight[0], topLeft[1],bottomLeft[1])\n",
    "            #row = to_pixel_coords(coords_1)\n",
    "            #column = to_pixel_coords(coords_2)\n",
    "\n",
    "            sliced_img = img2[topLeft[1]:bottomRight[1],topLeft[0]:bottomRight[0]]\n",
    "\n",
    "            cropped_aruco_dict[markerid] = sliced_img\n",
    "\n",
    "            cv2.imshow(\"sliced\",sliced_img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "521 106 154 568\n",
      "[[2]]\n",
      "535 70 13 479\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\OpenCV_Project_Codes_new.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000006?line=0'>1</a>\u001b[0m crop_aruco(aruco_dict[\u001b[39m1\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000006?line=1'>2</a>\u001b[0m crop_aruco(aruco_dict[\u001b[39m2\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000006?line=2'>3</a>\u001b[0m crop_aruco(aruco_dict[\u001b[39m3\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000006?line=3'>4</a>\u001b[0m crop_aruco(aruco_dict[\u001b[39m4\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\OpenCV_Project_Codes_new.ipynb Cell 6'\u001b[0m in \u001b[0;36mcrop_aruco\u001b[1;34m(img2)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000005?line=29'>30</a>\u001b[0m sliced_img \u001b[39m=\u001b[39m img2[topLeft[\u001b[39m1\u001b[39m]:bottomRight[\u001b[39m1\u001b[39m],topLeft[\u001b[39m0\u001b[39m]:bottomRight[\u001b[39m0\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000005?line=31'>32</a>\u001b[0m cropped_aruco_dict[markerid] \u001b[39m=\u001b[39m sliced_img\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000005?line=33'>34</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m\"\u001b[39;49m\u001b[39msliced\u001b[39;49m\u001b[39m\"\u001b[39;49m,sliced_img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000005?line=34'>35</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000005?line=35'>36</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "crop_aruco(aruco_dict[1])\n",
    "crop_aruco(aruco_dict[2])\n",
    "crop_aruco(aruco_dict[3])\n",
    "crop_aruco(aruco_dict[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Width and Height: 1754 x 1240\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\CVtask.jpg\")\n",
    "h,w,c = img1.shape\n",
    "print(\"Original Width and Height:\", w,\"x\", h)\n",
    "\n",
    "resized_img = cv2.resize(img1, (877,620))\n",
    "cv2.imshow(\"Original\",resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_Coloured_Squares(lower_bound,upper_bound):\n",
    "\n",
    "    mask = cv2.inRange(resized_img, lower_bound, upper_bound)\n",
    "\n",
    "    kernel = np.ones((7,7),np.uint8)\n",
    "    # Remove unnecessary noise from mask\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    segmented_img = cv2.bitwise_and(resized_img, resized_img, mask=mask)\n",
    "\n",
    "    img2 = segmented_img.copy()\n",
    "\n",
    "    l = 4\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 1000:\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,peri*0.04,True)\n",
    "            if len(approx) == l:\n",
    "            \n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                ar = w / float(h)\n",
    "\n",
    "                if ar >= 0.95 and ar <= 1.05:\n",
    "                    rect = cv2.minAreaRect(cnt)\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box = np.int0(box)\n",
    "                    cv2.drawContours(img2,[box],-1,(255,0,0),4)\n",
    "                    cv2.putText(img2,f\" {len(cnt)}\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,-1,(0,0,0),2)\n",
    "                    #cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                    print(x,y,w,h)\n",
    "                    print(rect,box)\n",
    "\n",
    "    cv2.imshow(\"image_contours\",img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 19 245 245\n",
      "((176.18589782714844, 140.789306640625), (205.82113647460938, 205.8515167236328), 13.47315788269043) [[ 52 216]\n",
      " [100  16]\n",
      " [300  64]\n",
      " [252 264]]\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Green color\n",
    "lower_bound_green = np.array([50, 20, 20])   \n",
    "upper_bound_green = np.array([100, 255, 255])\n",
    "\n",
    "detect_Coloured_Squares(lower_bound_green,upper_bound_green)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 39 175 175\n",
      "((673.0, 126.0), (174.0, 174.0), 90.0) [[586  39]\n",
      " [760  39]\n",
      " [760 213]\n",
      " [586 213]]\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Orange color\n",
    "lower_bound_orange = np.array([1,20,20])   \n",
    "upper_bound_orange = np.array([18, 255, 255])\n",
    "\n",
    "detect_Coloured_Squares(lower_bound_orange,upper_bound_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649 238 189 190\n",
      "((742.3639526367188, 332.4992370605469), (148.48709106445312, 148.56173706054688), 22.496471405029297) [[645 372]\n",
      " [702 235]\n",
      " [839 292]\n",
      " [782 429]]\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Black color\n",
    "lower_bound_black = np.array([0, 0, 0])   \n",
    "upper_bound_black = np.array([1, 1, 1])\n",
    "\n",
    "detect_Coloured_Squares(lower_bound_black,upper_bound_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower bound and upper bound for Pink Peach color\n",
    "lower_bound_pinkpeach = np.array([255, 219, 230])   \n",
    "upper_bound_pinkpeach = np.array([255, 240, 240])\n",
    "\n",
    "detect_Coloured_Squares(lower_bound_pinkpeach,upper_bound_pinkpeach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (200,200) into shape (0,248,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\OpenCV_Project_Codes_new.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000012?line=5'>6</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000012?line=7'>8</a>\u001b[0m large_img \u001b[39m=\u001b[39m segmented_img_green\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000012?line=9'>10</a>\u001b[0m large_img[\u001b[39m216\u001b[39m:\u001b[39m64\u001b[39m,\u001b[39m52\u001b[39m:\u001b[39m300\u001b[39m] \u001b[39m=\u001b[39m imgcanny\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000012?line=10'>11</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mlarge\u001b[39m\u001b[39m\"\u001b[39m,large_img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000012?line=11'>12</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (200,200) into shape (0,248,3)"
     ]
    }
   ],
   "source": [
    "resize1 = cv2.resize(aruco_dict[1],(200,200))\n",
    "gray = cv2.cvtColor(resize1,cv2.COLOR_BGR2GRAY)\n",
    "imgcanny = cv2.Canny(gray,30,150)\n",
    "cv2.imshow(\"canny\",imgcanny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#large_img = segmented_img.copy()\n",
    "\n",
    "large_img[216:64,52:300] = imgcanny\n",
    "cv2.imshow(\"large\",large_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:214: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\OpenCV_Project_Codes_new.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000011?line=0'>1</a>\u001b[0m bitand \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mbitwise_and(segmented_img_green,aruco_dict[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000011?line=1'>2</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m,bitand)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/OpenCV_Project_Spriha/OpenCV_Project_Codes_new.ipynb#ch0000011?line=2'>3</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:214: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "bitand = cv2.bitwise_and(segmented_img_green,aruco_dict[1])\n",
    "cv2.imshow(\"output\",bitand)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(np.max(bitand[220:600,220:1000]))\n",
    "print(np.min(bitand[220:600,220:1000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b337b16e1f284c9fe7de692799556d56c1809887abe3f5a49ffeb9e7df151cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
