{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_dict = {} #to store rotated aruco markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAruco(img): #to identify aruco marker ids and rotate to relevant angles\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    key = getattr(aruco,f'DICT_5X5_250')\n",
    "    arucoDict = aruco.Dictionary_get(key)\n",
    "    arucoPara = aruco.DetectorParameters_create()\n",
    "\n",
    "    (corners,ids,rejected) = cv2.aruco.detectMarkers(img, arucoDict, parameters = arucoPara)\n",
    "\n",
    "    print(ids)\n",
    "    if len(corners) > 0:\n",
    "        ids = ids.flatten()\n",
    "\n",
    "        for (markerCorner,markerid) in zip(corners,ids):\n",
    "            corners = markerCorner.reshape((4,2))\n",
    "            (topLeft,topRight,bottomLeft,bottomRight) = corners\n",
    "\n",
    "            topRight = (int(topRight[0]),int(topRight[1]))\n",
    "            topLeft = (int(topLeft[0]),int(topLeft[1])) \n",
    "            bottomLeft = (int(bottomLeft[0]),int(bottomLeft[1]))\n",
    "            bottomRight = (int(bottomRight[0]),int(bottomRight[1]))\n",
    "\n",
    "            cx = int((topLeft[0]+bottomRight[0])/2.0) #centre coordinates\n",
    "            cy = int((topLeft[1]+bottomRight[1])/2.0)\n",
    "\n",
    "            cx1 = int((topLeft[0]+bottomLeft[0])/2.0) #centre of one edge\n",
    "            cy1 = int((topLeft[1]+bottomLeft[1])/2.0)\n",
    "\n",
    "            imgcopy = img.copy()\n",
    "\n",
    "            cv2.circle(imgcopy, (cx,cy),5,(255,0,0),-1)\n",
    "            cv2.circle(imgcopy, (cx1,cy1),5,(255,0,0),-1)\n",
    "            cv2.line(imgcopy,(cx,cy),(cx1,cy1),(255,0,0),2)\n",
    "\n",
    "            slope = (cy1-cy)/(cx1-cx)\n",
    "            angle = (math.atan(slope)) * 180 / math.pi\n",
    "            cv2.putText(imgcopy,str(angle),(cx,cy+10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "\n",
    "            cv2.imshow(\"Display angle\",imgcopy)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            # Generating a rotation matrix \n",
    "\n",
    "            matrix = cv2.getRotationMatrix2D((cx,cy), angle, 1.0) \n",
    "            h,w,c = img.shape\n",
    "\n",
    "            # Performing the affine transformation \n",
    "\n",
    "            rotated = cv2.warpAffine(img, matrix, (w, h))\n",
    "\n",
    "        \n",
    "            aruco_dict[markerid] = rotated\n",
    "            \n",
    "            cv2.imshow(\"Rotated image\",rotated)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]]\n",
      "[[4]]\n",
      "[[1]]\n",
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "img_a = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\Ha.jpg\")\n",
    "img_b = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\HaHa.jpg\")\n",
    "img_c = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\LMAO.jpg\")\n",
    "img_d = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\XD.jpg\")\n",
    "\n",
    "findAruco(img_a)\n",
    "findAruco(img_b)\n",
    "findAruco(img_c)\n",
    "findAruco(img_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crop aruco markers to remove extra boundary area\n",
    "\n",
    "cropped_aruco_1 = aruco_dict[1][150:570,105:515]\n",
    "cropped_aruco_2 = aruco_dict[2][13:478,70:535]\n",
    "cropped_aruco_3 = aruco_dict[3][77:515,77:515]\n",
    "cropped_aruco_4 = aruco_dict[4][130:566,85:521]\n",
    "\n",
    "cropped_aruco_dict = {1:cropped_aruco_1,2:cropped_aruco_2,3:cropped_aruco_3,4:cropped_aruco_4}\n",
    "\n",
    "cv2.imshow(\"cropped_1\",cropped_aruco_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"cropped_2\",cropped_aruco_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"cropped_3\",cropped_aruco_3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"cropped_4\",cropped_aruco_4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the corner coordinates of the cropped aruco markers\n",
    "aruco_coord_dict = {}\n",
    "\n",
    "for i in range(1,5):\n",
    "   \n",
    "    coordinates = [[0, cropped_aruco_dict[i].shape[1]], [0, 0], [cropped_aruco_dict[i].shape[1], 0],[cropped_aruco_dict[i].shape[1], cropped_aruco_dict[i].shape[0]]]\n",
    "    aruco_coord_dict[i] = coordinates\n",
    "\n",
    "aruco_coord_dict[2] = [[0, 0], [cropped_aruco_dict[i].shape[1], 0],[cropped_aruco_dict[i].shape[1], cropped_aruco_dict[i].shape[0]], [0, cropped_aruco_dict[i].shape[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Width and Height: 1754 x 1240\n"
     ]
    }
   ],
   "source": [
    "#Open the initial task image and resize it\n",
    "img1 = cv2.imread(r\"C:\\Users\\HP\\OneDrive\\Desktop\\OpenCV_Project_Spriha\\CVtask.jpg\")\n",
    "h,w,c = img1.shape\n",
    "print(\"Original Width and Height:\", w,\"x\", h)\n",
    "\n",
    "resized_img = cv2.resize(img1, (877,620))\n",
    "cv2.imshow(\"Original\",resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_coord_dict = {} #to store corner coordinates of all squares of different colours\n",
    "width_height = {} #to store the width and height of the square boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to detect squares among similar coloured shapes\n",
    "#lower_bound and upper_bound specifies the rgb range of colour\n",
    "\n",
    "def detect_Coloured_Squares(colour,lower_bound,upper_bound):\n",
    "\n",
    "    mask = cv2.inRange(resized_img, lower_bound, upper_bound)\n",
    "\n",
    "    kernel = np.ones((7,7),np.uint8)\n",
    "    # Remove unnecessary noise from mask\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    segmented_img = cv2.bitwise_and(resized_img, resized_img, mask=mask) #only the specified coloured portions in the image are displayed\n",
    "\n",
    "    img2 = segmented_img.copy()\n",
    "\n",
    "    l = 4\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 1000:\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,peri*0.04,True)\n",
    "            if len(approx) == l:\n",
    "            \n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                ar = w / float(h)\n",
    "\n",
    "                if ar >= 0.95 and ar <= 1.05:  #conditions for square image\n",
    "\n",
    "                    rect = cv2.minAreaRect(cnt) #to bound in a particular angle\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box = np.int0(box)\n",
    "                    cv2.drawContours(img2,[box],-1,(255,0,0),4)\n",
    "                    cv2.putText(img2,f\" {len(cnt)}\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,-1,(0,0,0),2)\n",
    "                    #cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                    print(rect,box)\n",
    "\n",
    "                    lst_coord = []    #get the x and y coordinates for all four corners\n",
    "\n",
    "                    lst_coord_0 = [list(box)[0][0],list(box)[0][1]] \n",
    "                    lst_coord.append(lst_coord_0)\n",
    "\n",
    "                    lst_coord_1 = [list(box)[1][0],list(box)[1][1]]\n",
    "                    lst_coord.append(lst_coord_1)\n",
    "\n",
    "                    lst_coord_2 = [list(box)[2][0],list(box)[2][1]]\n",
    "                    lst_coord.append(lst_coord_2)\n",
    "\n",
    "                    lst_coord_3 = [list(box)[3][0],list(box)[3][1]]\n",
    "                    lst_coord.append(lst_coord_3)\n",
    "                   \n",
    "                    print(\"Corner points of box: \",lst_coord)\n",
    "                    print(\"Width and height: \",rect[1])\n",
    "                    \n",
    "                    colour_coord_dict[colour] = lst_coord\n",
    "                    width_height[colour] = rect[1]\n",
    "\n",
    "    cv2.imshow(\"image_contours\",img2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((176.18589782714844, 140.789306640625), (205.82113647460938, 205.8515167236328), 13.47315788269043) [[ 52 216]\n",
      " [100  16]\n",
      " [300  64]\n",
      " [252 264]]\n",
      "Corner points of box:  [[52, 216], [100, 16], [300, 64], [252, 264]]\n",
      "Width and height:  (205.82113647460938, 205.8515167236328)\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Green color\n",
    "colour_green = \"green\"\n",
    "lower_bound_green = np.array([60, 60, 60])   \n",
    "upper_bound_green = np.array([100, 255, 255])\n",
    "\n",
    "detect_Coloured_Squares(colour_green,lower_bound_green,upper_bound_green)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((673.0, 126.0), (174.0, 174.0), 90.0) [[586  39]\n",
      " [760  39]\n",
      " [760 213]\n",
      " [586 213]]\n",
      "Corner points of box:  [[586, 39], [760, 39], [760, 213], [586, 213]]\n",
      "Width and height:  (174.0, 174.0)\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Orange color\n",
    "colour_orange = \"orange\"\n",
    "lower_bound_orange = np.array([1,20,20])   \n",
    "upper_bound_orange = np.array([18, 255, 255])\n",
    "\n",
    "detect_Coloured_Squares(colour_orange,lower_bound_orange,upper_bound_orange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((742.3639526367188, 332.4992370605469), (148.48709106445312, 148.56173706054688), 22.496471405029297) [[645 372]\n",
      " [702 235]\n",
      " [839 292]\n",
      " [782 429]]\n",
      "Corner points of box:  [[645, 372], [702, 235], [839, 292], [782, 429]]\n",
      "Width and height:  (148.48709106445312, 148.56173706054688)\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Black color\n",
    "colour_black = \"black\"\n",
    "lower_bound_black = np.array([0, 0, 0])   \n",
    "upper_bound_black = np.array([1, 1, 1])\n",
    "\n",
    "detect_Coloured_Squares(colour_black,lower_bound_black,upper_bound_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((345.5838623046875, 388.7042236328125), (266.1113586425781, 266.0950927734375), 61.352386474609375) [[165 335]\n",
      " [398 208]\n",
      " [526 441]\n",
      " [292 569]]\n",
      "Corner points of box:  [[165, 335], [398, 208], [526, 441], [292, 569]]\n",
      "Width and height:  (266.1113586425781, 266.0950927734375)\n"
     ]
    }
   ],
   "source": [
    "# lower bound and upper bound for Pink Peach color\n",
    "colour_pinkpeach = \"pink-peach\"\n",
    "lower_bound_pinkpeach = np.array([200, 200, 200])   \n",
    "upper_bound_pinkpeach = np.array([245, 245, 245])\n",
    "\n",
    "detect_Coloured_Squares(colour_pinkpeach,lower_bound_pinkpeach,upper_bound_pinkpeach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_parts = {} #stores images of all the aruco markers pasted one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_aruco(j,colour):\n",
    "    pts_src = np.array(aruco_coord_dict[j]) #coordinates of all four corners of the aruco markers\n",
    "\n",
    "    pts_dst = np.array(colour_coord_dict[colour]) #roi corresponding to the specific colour according to marker id\n",
    "\n",
    "    # Calculate Homography\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "    im_out = cv2.warpPerspective(cropped_aruco_dict[j], h, (resized_img.shape[1],resized_img.shape[0])) #arucomarker placed on the specified coordinates\n",
    "\n",
    "    final_parts[j] = im_out\n",
    "\n",
    "    cv2.imshow(\"Warped Source Image\", im_out)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_aruco(1,\"green\")\n",
    "place_aruco(2,\"orange\")\n",
    "place_aruco(3,\"black\")\n",
    "place_aruco(4,\"pink-peach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roi areas are turned black(pixels=0) \n",
    "resized_img = cv2.fillConvexPoly(resized_img, np.array(colour_coord_dict[\"green\"]), (0,0,0))\n",
    "resized_img = cv2.fillConvexPoly(resized_img, np.array(colour_coord_dict[\"orange\"]), (0,0,0))\n",
    "resized_img = cv2.fillConvexPoly(resized_img, np.array(colour_coord_dict[\"black\"]), (0,0,0))\n",
    "resized_img = cv2.fillConvexPoly(resized_img, np.array(colour_coord_dict[\"pink-peach\"]), (0,0,0))\n",
    "\n",
    "for i in range(1,5):\n",
    "\n",
    "    newmask = np.array(np.zeros(resized_img.shape))\n",
    "    newmask = cv2.fillConvexPoly(newmask,np.array(aruco_coord_dict[i]),(255,255,255))\n",
    "\n",
    "    kernel1 = np.ones((7,7),np.uint8)\n",
    "    newmask = cv2.morphologyEx(newmask, cv2.MORPH_CLOSE, kernel1)\n",
    "    newmask = cv2.morphologyEx(newmask, cv2.MORPH_OPEN, kernel1)\n",
    "\n",
    "    th = cv2.bitwise_and(final_parts[i],final_parts[i], newmask) #combining the mask with the task image\n",
    "\n",
    "    resized_img += final_parts[i]   #the final_parts are put together in one final image\n",
    "    cv2.imshow(\"placed_aruco\",resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"final\",resized_img)\n",
    "\n",
    "cv2.imwrite(\"Final.jpg\",resized_img) #the final image file is saved\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b337b16e1f284c9fe7de692799556d56c1809887abe3f5a49ffeb9e7df151cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
